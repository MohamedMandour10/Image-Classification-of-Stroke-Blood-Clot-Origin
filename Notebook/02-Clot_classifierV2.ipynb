{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 10421033,
          "sourceType": "datasetVersion",
          "datasetId": 6458926
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Clot-classifierV2",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages"
      ],
      "metadata": {
        "id": "gVmY7__N-kdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import recall_score, f1_score\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from huggingface_hub import HfApi, login, HfFolder\n",
        "login()"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T12:54:06.773831Z",
          "iopub.execute_input": "2025-01-10T12:54:06.774144Z",
          "iopub.status.idle": "2025-01-10T12:54:12.649926Z",
          "shell.execute_reply.started": "2025-01-10T12:54:06.774118Z",
          "shell.execute_reply": "2025-01-10T12:54:12.649009Z"
        },
        "id": "28fX9Y1q-EUd",
        "outputId": "3c521eeb-5755-4ac2-c759-f4cfb4edc43f",
        "colab": {
          "referenced_widgets": [
            "e22afc6a541049c192ccc974b428d7e7"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e22afc6a541049c192ccc974b428d7e7"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
        "import time\n",
        "import wandb\n",
        "\n",
        "API-KEY = \"\"\n",
        "wandb.login(key=API-KEY)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T12:54:22.174438Z",
          "iopub.execute_input": "2025-01-10T12:54:22.174816Z",
          "iopub.status.idle": "2025-01-10T12:54:32.34955Z",
          "shell.execute_reply.started": "2025-01-10T12:54:22.174786Z",
          "shell.execute_reply": "2025-01-10T12:54:32.348802Z"
        },
        "id": "tSTcc41I-EUg",
        "outputId": "d837139c-5e11-4ed8-e28b-b16331ff8b7a"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmandour\u001b[0m (\u001b[33mmandour-cairo-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        },
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SEED for reproducability"
      ],
      "metadata": {
        "id": "gWGG9f_1-w7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "seed = 10\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T12:54:32.350452Z",
          "iopub.execute_input": "2025-01-10T12:54:32.350947Z",
          "iopub.status.idle": "2025-01-10T12:54:32.409725Z",
          "shell.execute_reply.started": "2025-01-10T12:54:32.350922Z",
          "shell.execute_reply": "2025-01-10T12:54:32.408991Z"
        },
        "id": "tWHVV1Nz-EUh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data from Hugging face"
      ],
      "metadata": {
        "id": "4Hdpnw4B-EUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "def download_and_extract_zip(repo_id, file_name, output_dir, repo_type=\"dataset\"):\n",
        "    \"\"\"\n",
        "    Downloads a zip file from a Hugging Face repository and extracts its contents.\n",
        "\n",
        "    Args:\n",
        "        repo_id (str): The repository ID in the form 'namespace/repo_name'.\n",
        "        file_name (str): The name of the zip file in the repository.\n",
        "        output_dir (str): Directory to extract the contents of the zip file.\n",
        "        repo_type (str): The type of the repository ('model', 'dataset', or 'space').\n",
        "    \"\"\"\n",
        "    # Download the zip file\n",
        "    zip_file_path = hf_hub_download(repo_id=repo_id, filename=file_name, repo_type=repo_type)\n",
        "    print(f\"Downloaded '{file_name}' from '{repo_id}' to '{zip_file_path}'.\")\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Extract the zip file\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(output_dir)\n",
        "    print(f\"Extracted contents to '{output_dir}'.\")\n",
        "\n",
        "# Example usage\n",
        "repo_id = ...\n",
        "file_name = ...\n",
        "output_dir = ...\n",
        "\n",
        "download_and_extract_zip(repo_id, file_name, output_dir)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T12:54:39.654633Z",
          "iopub.execute_input": "2025-01-10T12:54:39.65499Z",
          "iopub.status.idle": "2025-01-10T13:03:26.617688Z",
          "shell.execute_reply.started": "2025-01-10T12:54:39.654964Z",
          "shell.execute_reply": "2025-01-10T13:03:26.616777Z"
        },
        "id": "t-gzozlP-EUq",
        "outputId": "46f9c992-6f84-4672-9212-5bddded851c9",
        "colab": {
          "referenced_widgets": [
            "1a7092684819444b94723b07df210057"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "output.zip:   0%|          | 0.00/13.2G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a7092684819444b94723b07df210057"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Downloaded 'output.zip' from 'Mandour-101/Strip-img-resized-224' to '/root/.cache/huggingface/hub/datasets--Mandour-101--Strip-img-resized-224/snapshots/6c6db3881b805ba8f407c09809607d596f214d36/output.zip'.\nExtracted contents to '/kaggle/working/unzipped_files'.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dataframe and Pipeline"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-01-07T23:58:01.093705Z",
          "iopub.execute_input": "2025-01-07T23:58:01.094045Z",
          "iopub.status.idle": "2025-01-07T23:58:01.097648Z",
          "shell.execute_reply.started": "2025-01-07T23:58:01.09402Z",
          "shell.execute_reply": "2025-01-07T23:58:01.096723Z"
        },
        "id": "Hsd3lcP--EUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid = pd.read_csv(\"/kaggle/input/valid-data2/valid_imagesV2.csv\")\n",
        "df_valid"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:26.61901Z",
          "iopub.execute_input": "2025-01-10T13:03:26.619352Z",
          "iopub.status.idle": "2025-01-10T13:03:26.830631Z",
          "shell.execute_reply.started": "2025-01-10T13:03:26.619317Z",
          "shell.execute_reply": "2025-01-10T13:03:26.82968Z"
        },
        "id": "htbeSusy-EUs",
        "outputId": "29d504e3-198f-4092-cf88-dc525ede0cb9"
      },
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                     path  label\n0       /kaggle/working/unzipped_files/LAA/fbdcde_1_19...      1\n1       /kaggle/working/unzipped_files/LAA/f83bf0_0_16...      1\n2       /kaggle/working/unzipped_files/LAA/6baf51_0_14...      1\n3       /kaggle/working/unzipped_files/LAA/c9ab6c_0_5_...      1\n4       /kaggle/working/unzipped_files/LAA/fbdcde_0_28...      1\n...                                                   ...    ...\n118631  /kaggle/working/unzipped_files/CE/dc8f86_1_1_1...      0\n118632  /kaggle/working/unzipped_files/CE/cb2534_1_10_...      0\n118633  /kaggle/working/unzipped_files/CE/f58fcb_0_23_...      0\n118634  /kaggle/working/unzipped_files/CE/f57f2e_0_15_...      0\n118635  /kaggle/working/unzipped_files/CE/19b036_0_9_5...      0\n\n[118636 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/working/unzipped_files/LAA/fbdcde_1_19...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/working/unzipped_files/LAA/f83bf0_0_16...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/working/unzipped_files/LAA/6baf51_0_14...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/working/unzipped_files/LAA/c9ab6c_0_5_...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/working/unzipped_files/LAA/fbdcde_0_28...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>118631</th>\n      <td>/kaggle/working/unzipped_files/CE/dc8f86_1_1_1...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>118632</th>\n      <td>/kaggle/working/unzipped_files/CE/cb2534_1_10_...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>118633</th>\n      <td>/kaggle/working/unzipped_files/CE/f58fcb_0_23_...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>118634</th>\n      <td>/kaggle/working/unzipped_files/CE/f57f2e_0_15_...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>118635</th>\n      <td>/kaggle/working/unzipped_files/CE/19b036_0_9_5...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>118636 rows Ã— 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot random samples with labels\n",
        "def plot_random_samples(df, num_samples=5):\n",
        "    # Randomly sample 'num_samples' rows from the dataframe\n",
        "    sampled_df = df.sample(n=num_samples)\n",
        "\n",
        "    # Set up the plot grid (e.g., 1 row, num_samples columns)\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
        "\n",
        "    # Loop through the sampled images and display them\n",
        "    for i, (index, row) in enumerate(sampled_df.iterrows()):\n",
        "        image_path = row['path']\n",
        "        label = row['label']\n",
        "\n",
        "        # Load and display the image\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].axis('off')  # Hide axis\n",
        "\n",
        "        # Set title with label\n",
        "        axes[i].set_title(f\"Label: {label}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_random_samples(df_valid, num_samples=5)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T12:54:35.269955Z",
          "iopub.execute_input": "2025-01-10T12:54:35.270276Z",
          "iopub.status.idle": "2025-01-10T12:54:35.275495Z",
          "shell.execute_reply.started": "2025-01-10T12:54:35.270249Z",
          "shell.execute_reply": "2025-01-10T12:54:35.274605Z"
        },
        "id": "fJAIlceO-EUl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting data to train, val, and test"
      ],
      "metadata": {
        "id": "leaVnBmj_AqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_temp = train_test_split(df_valid, test_size=0.2, random_state=42)\n",
        "df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:26.832455Z",
          "iopub.execute_input": "2025-01-10T13:03:26.83281Z",
          "iopub.status.idle": "2025-01-10T13:03:33.378073Z",
          "shell.execute_reply.started": "2025-01-10T13:03:26.832777Z",
          "shell.execute_reply": "2025-01-10T13:03:33.377339Z"
        },
        "id": "EL7WusHB-EUs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataset and Dataloaders"
      ],
      "metadata": {
        "id": "aEJQXbye_JCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "   def __init__(self, df, transform=None):\n",
        "       self.df = df\n",
        "       self.transform = transform or transforms.Compose([\n",
        "           transforms.Resize((224, 224)),\n",
        "           transforms.ToTensor(),\n",
        "           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "       ])\n",
        "\n",
        "   def __len__(self):\n",
        "       return len(self.df)\n",
        "\n",
        "   def __getitem__(self, idx):\n",
        "       img_path = self.df.iloc[idx][\"path\"]\n",
        "       label = self.df.iloc[idx][\"label\"]\n",
        "\n",
        "       image = Image.open(img_path).convert(\"RGB\")\n",
        "       image = self.transform(image)\n",
        "       return image, torch.tensor(label, dtype=torch.long)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:33.379381Z",
          "iopub.execute_input": "2025-01-10T13:03:33.379734Z",
          "iopub.status.idle": "2025-01-10T13:03:33.78484Z",
          "shell.execute_reply.started": "2025-01-10T13:03:33.379699Z",
          "shell.execute_reply": "2025-01-10T13:03:33.783858Z"
        },
        "id": "FAKWgVjH-EUs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation"
      ],
      "metadata": {
        "id": "_4WGVsBE_QqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
        "    transforms.RandomRotation(degrees=45),\n",
        "    transforms.ColorJitter(brightness=0.2, hue=0.3, saturation=0.3),\n",
        "    transforms.ToTensor(),  # Convert PIL image to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),  # Convert PIL image to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:33.785756Z",
          "iopub.execute_input": "2025-01-10T13:03:33.78605Z",
          "iopub.status.idle": "2025-01-10T13:03:37.051775Z",
          "shell.execute_reply.started": "2025-01-10T13:03:33.78602Z",
          "shell.execute_reply": "2025-01-10T13:03:37.050283Z"
        },
        "id": "YCymbEhH-EUs",
        "outputId": "7f75e2ff-99fa-4ac3-988c-c2c0538700df"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Train loader:\nImage batch shape: torch.Size([32, 3, 224, 224])\nLabels batch shape: torch.Size([32])\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets\n",
        "train_dataset = ImageDataset(df_train, transform= train_transform)\n",
        "val_dataset = ImageDataset(df_val, transform= val_test_transform)\n",
        "test_dataset = ImageDataset(df_test, transform= val_test_transform)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    print(\"Train loader:\")\n",
        "    print(f\"Image batch shape: {images.shape}\")\n",
        "    print(f\"Labels batch shape: {labels.shape}\")\n",
        "    break  # Only print for the first batch, to avoid printing too much"
      ],
      "metadata": {
        "id": "MJk-g6vM_XTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class count for imbalance in the data"
      ],
      "metadata": {
        "id": "lGMq3ngD_am2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class\n",
        "class_counts = df_valid['label'].value_counts()\n",
        "\n",
        "# Total number of samples\n",
        "total_samples = len(df_valid)\n",
        "\n",
        "# Calculate weights as inverse frequency\n",
        "class_weights = total_samples / class_counts\n",
        "\n",
        "# Convert to a PyTorch tensor\n",
        "class_weights_tensor = torch.tensor(class_weights.values, dtype=torch.float32)\n",
        "\n",
        "# Map weights to class indices\n",
        "class_to_weight = dict(zip(class_counts.index, class_weights))\n",
        "print(\"Class Weights Mapping:\", class_to_weight)\n",
        "print(\"PyTorch Class Weights Tensor:\", class_weights_tensor)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:37.053421Z",
          "iopub.execute_input": "2025-01-10T13:03:37.053803Z",
          "iopub.status.idle": "2025-01-10T13:03:37.155378Z",
          "shell.execute_reply.started": "2025-01-10T13:03:37.053766Z",
          "shell.execute_reply": "2025-01-10T13:03:37.154446Z"
        },
        "id": "esJfw21m-EUs",
        "outputId": "30ba27ed-a594-4d3a-f3a4-8d2086eb5620"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Class Weights Mapping: {0: 1.531696232602577, 1: 2.8807731533194114}\nPyTorch Class Weights Tensor: tensor([1.5317, 2.8808])\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "fMiFsSJ1_git"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PoolFormer class Wrapper"
      ],
      "metadata": {
        "id": "u5loTHc-_jjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timm import create_model\n",
        "\n",
        "def create_optimized_poolformer36_model(num_classes=2, dropout_rate=0.3, trainable_backbone_layers=10):\n",
        "    \"\"\"\n",
        "    Creates a Poolformer model with improvements for better performance and reduced overfitting.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int): Number of output classes.\n",
        "        dropout_rate (float): Dropout rate for the classifier head.\n",
        "        trainable_backbone_layers (int): Number of trainable backbone layers from the end.\n",
        "        use_label_smoothing (bool): Whether to apply label smoothing.\n",
        "\n",
        "    Returns:\n",
        "        nn.Module: Optimized Poolformer model ready for fine-tuning.\n",
        "    \"\"\"\n",
        "    # Create the base Poolformer model\n",
        "    model = create_model('poolformer_s36', pretrained=True)\n",
        "\n",
        "    # Freeze all layers by default\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Unfreeze the last `trainable_backbone_layers` stages in the backbone\n",
        "    if hasattr(model, \"stages\"):\n",
        "        for stage in model.stages[-trainable_backbone_layers:]:\n",
        "            for param in stage.parameters():\n",
        "                param.requires_grad = True\n",
        "    else:\n",
        "        raise AttributeError(\"The Poolformer model does not have the expected 'stages' attribute.\")\n",
        "\n",
        "    # Modify the classifier head\n",
        "    if hasattr(model.head, \"fc\"):  # Access the fully connected layer in the head\n",
        "        in_features = model.head.fc.in_features\n",
        "        model.head.fc = nn.Sequential(\n",
        "            nn.BatchNorm1d(in_features),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(in_features, in_features // 2),  # Intermediate dense layer\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(in_features // 2),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(in_features // 2, num_classes)\n",
        "        )\n",
        "    else:\n",
        "        raise AttributeError(\"The Poolformer model does not have the expected 'fc' in the head.\")\n",
        "\n",
        "    # Ensure classifier head is trainable\n",
        "    for param in model.head.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 2\n",
        "dropout_rate = 0.5  # Increased dropout rate to reduce overfitting\n",
        "trainable_backbone_layers = 12 # Fine-tune more layers in the backbone\n",
        "\n",
        "# Create the optimized model\n",
        "model = create_optimized_poolformer36_model(\n",
        "    num_classes=num_classes,\n",
        "    dropout_rate=dropout_rate,\n",
        "    trainable_backbone_layers=trainable_backbone_layers,).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:37.156339Z",
          "iopub.execute_input": "2025-01-10T13:03:37.156672Z",
          "iopub.status.idle": "2025-01-10T13:03:44.3021Z",
          "shell.execute_reply.started": "2025-01-10T13:03:37.156618Z",
          "shell.execute_reply": "2025-01-10T13:03:44.301378Z"
        },
        "id": "5YZoULeB-EUt",
        "outputId": "d7bb2822-e115-4a0a-bb06-e049761732e9",
        "colab": {
          "referenced_widgets": [
            "0c4b421a122a44f8a69fe64cf6176100"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/123M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c4b421a122a44f8a69fe64cf6176100"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainerConfig:\n",
        "    def __init__(self):\n",
        "        self.num_classes = 2\n",
        "        self.patience = 3\n",
        "        self.min_delta = 1e-4\n",
        "        self.plot_interval = 2\n",
        "        self.max_grad_norm = 1.0\n",
        "        self.early_stop_metric = 'loss'\n",
        "        self.learning_rate = 3e-4\n",
        "        self.weight_decay = 1e-5"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:44.304557Z",
          "iopub.execute_input": "2025-01-10T13:03:44.304834Z",
          "iopub.status.idle": "2025-01-10T13:03:44.308902Z",
          "shell.execute_reply.started": "2025-01-10T13:03:44.304809Z",
          "shell.execute_reply": "2025-01-10T13:03:44.307989Z"
        },
        "id": "oPYgZdDi-EUt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function $WMCLL$"
      ],
      "metadata": {
        "id": "kvNxNiDY_sMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightedMultiClassLogLoss(nn.Module):\n",
        "    def __init__(self, class_weights=None, device=None):\n",
        "        \"\"\"\n",
        "        Initializes the Weighted Multi-Class Log Loss (WMCLL).\n",
        "\n",
        "        Args:\n",
        "            class_weights (torch.Tensor): A tensor of shape (num_classes,) containing weights for each class.\n",
        "            device (torch.device): The device to perform the computation on.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.device = device if device else torch.device('cpu')\n",
        "        self.class_weights = class_weights.to(self.device) if class_weights is not None else None\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        \"\"\"\n",
        "        Computes the Weighted Multi-Class Log Loss.\n",
        "\n",
        "        Args:\n",
        "            logits (torch.Tensor): Predicted logits of shape (batch_size, num_classes).\n",
        "            targets (torch.Tensor): Ground truth of shape (batch_size, num_classes) as one-hot encoded.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The computed weighted multi-class log loss.\n",
        "        \"\"\"\n",
        "        logits, targets = logits.to(self.device), targets.to(self.device)\n",
        "\n",
        "        if self.class_weights is not None:\n",
        "            weights = self.class_weights.to(self.device)\n",
        "        else:\n",
        "            weights = torch.ones(logits.size(1), device=self.device)\n",
        "\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        log_probs = torch.log(probs + 1e-8)\n",
        "        weighted_log_loss = -torch.sum(weights * targets * log_probs, dim=1)\n",
        "        loss = torch.mean(weighted_log_loss)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:44.310403Z",
          "iopub.execute_input": "2025-01-10T13:03:44.310613Z",
          "iopub.status.idle": "2025-01-10T13:03:44.325528Z",
          "shell.execute_reply.started": "2025-01-10T13:03:44.310594Z",
          "shell.execute_reply": "2025-01-10T13:03:44.324642Z"
        },
        "id": "ekRMny74-EUt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer Class"
      ],
      "metadata": {
        "id": "yhSxJqxE-EUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, criterion, config=None):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model = model.to(self.device)\n",
        "        self.criterion = criterion\n",
        "        self.config = config\n",
        "\n",
        "        # Initialize optimizer and scheduler\n",
        "        self.optimizer = optim.AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=self.config.learning_rate,\n",
        "            weight_decay=self.config.weight_decay\n",
        "        )\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer,\n",
        "            mode='min',\n",
        "            patience=2,\n",
        "            factor=0.5,\n",
        "            min_lr=1e-6\n",
        "        )\n",
        "\n",
        "        # Initialize metrics with macro averaging\n",
        "        self.metrics = {\n",
        "            'accuracy': Accuracy(task='multiclass', num_classes=self.config.num_classes, average='macro').to(self.device),\n",
        "            'precision': Precision(task='multiclass', num_classes=self.config.num_classes, average='macro').to(self.device),\n",
        "            'recall': Recall(task='multiclass', num_classes=self.config.num_classes, average='macro').to(self.device),\n",
        "            'f1': F1Score(task='multiclass', num_classes=self.config.num_classes, average='macro').to(self.device)\n",
        "        }\n",
        "\n",
        "        # Initialize training state\n",
        "        self.best_model = None\n",
        "        self.best_metric = float('inf') if self.config.early_stop_metric == 'loss' else float('-inf')\n",
        "        self.history = {'train': [], 'val': []}\n",
        "        self.epochs_without_improve = 0\n",
        "\n",
        "        # Initialize W&B\n",
        "        self.run = wandb.init(\n",
        "            project=config.project_name,\n",
        "            config={\n",
        "                \"learning_rate\": config.learning_rate,\n",
        "                \"weight_decay\": config.weight_decay,\n",
        "                \"batch_size\": config.batch_size,\n",
        "                \"epochs\": config.epochs,\n",
        "                \"model\": model.__class__.__name__\n",
        "            }\n",
        "        )\n",
        "        wandb.watch(model)\n",
        "\n",
        "    def reset_metrics(self):\n",
        "        \"\"\"Reset all metrics at the start of each epoch\"\"\"\n",
        "        for metric in self.metrics.values():\n",
        "            metric.reset()\n",
        "\n",
        "    def validate(self, val_loader):\n",
        "        \"\"\"Validate the model on the validation set\"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        total_samples = 0\n",
        "        self.reset_metrics()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                batch_size = inputs.size(0)\n",
        "                total_samples += batch_size\n",
        "\n",
        "                outputs = self.model(inputs)\n",
        "                one_hot = nn.functional.one_hot(labels, self.config.num_classes).float()\n",
        "                total_loss += self.criterion(outputs, one_hot).item() * batch_size\n",
        "\n",
        "                preds = outputs.argmax(1)\n",
        "                for metric in self.metrics.values():\n",
        "                    metric.update(preds, labels)\n",
        "\n",
        "        metrics_dict = {\n",
        "            'loss': total_loss / total_samples,\n",
        "            'accuracy': self.metrics['accuracy'].compute().item(),\n",
        "            'precision': self.metrics['precision'].compute().item(),\n",
        "            'recall': self.metrics['recall'].compute().item(),\n",
        "            'f1': self.metrics['f1'].compute().item()\n",
        "        }\n",
        "        wandb.log({f\"val_{k}\": v for k, v in metrics_dict.items()})\n",
        "        return metrics_dict\n",
        "\n",
        "    def train_epoch(self, train_loader, epoch_idx):\n",
        "        \"\"\"Train for one epoch and log metrics against batches.\"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        total_samples = 0\n",
        "        self.reset_metrics()\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(tqdm(train_loader, desc=f\"Training Epoch {epoch_idx + 1}\")):\n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            batch_size = inputs.size(0)\n",
        "            total_samples += batch_size\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(inputs)\n",
        "            one_hot = nn.functional.one_hot(labels, self.config.num_classes).float()\n",
        "            loss = self.criterion(outputs, one_hot)\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * batch_size\n",
        "            preds = outputs.argmax(1)\n",
        "            for metric in self.metrics.values():\n",
        "                metric.update(preds, labels)\n",
        "\n",
        "            # Compute batch metrics\n",
        "            batch_metrics = {\n",
        "                'loss': loss.item(),\n",
        "                'accuracy': self.metrics['accuracy'].compute().item(),\n",
        "                'precision': self.metrics['precision'].compute().item(),\n",
        "                'recall': self.metrics['recall'].compute().item(),\n",
        "                'f1': self.metrics['f1'].compute().item()\n",
        "            }\n",
        "\n",
        "            # Log metrics to W&B\n",
        "            wandb.log({f\"train_batch_{k}\": v for k, v in batch_metrics.items()}, step=epoch_idx * len(train_loader) + batch_idx)\n",
        "\n",
        "        # Compute epoch-level metrics\n",
        "        epoch_metrics = {\n",
        "            'loss': total_loss / total_samples,\n",
        "            'accuracy': self.metrics['accuracy'].compute().item(),\n",
        "            'precision': self.metrics['precision'].compute().item(),\n",
        "            'recall': self.metrics['recall'].compute().item(),\n",
        "            'f1': self.metrics['f1'].compute().item()\n",
        "        }\n",
        "        wandb.log({f\"train_epoch_{k}\": v for k, v in epoch_metrics.items()}, step=epoch_idx + 1)\n",
        "\n",
        "        return epoch_metrics\n",
        "\n",
        "    def train(self, train_loader, val_loader, epochs=10):\n",
        "        \"\"\"Main training loop\"\"\"\n",
        "        print(f\"Starting training on device: {self.device}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            epoch_start = time.time()\n",
        "\n",
        "            # Training phase\n",
        "            train_metrics = self.train_epoch(train_loader, epoch)\n",
        "\n",
        "            # Validation phase\n",
        "            val_metrics = self.validate(val_loader)\n",
        "\n",
        "            # Update learning rate\n",
        "            self.scheduler.step(val_metrics['loss'])\n",
        "\n",
        "            # Store history\n",
        "            self.history['train'].append(train_metrics)\n",
        "            self.history['val'].append(val_metrics)\n",
        "\n",
        "            # Print progress\n",
        "            epoch_time = time.time() - epoch_start\n",
        "            print(f\"\\nEpoch {epoch + 1}/{epochs} - Time: {epoch_time:.2f}s\")\n",
        "            print(\"Train:\", \" \".join(f\"{k}: {v:.4f}\" for k, v in train_metrics.items()))\n",
        "            print(\"Val:\", \" \".join(f\"{k}: {v:.4f}\" for k, v in val_metrics.items()))\n",
        "\n",
        "            # Check for improvement\n",
        "            current = val_metrics[self.config.early_stop_metric]\n",
        "            improved = (self.config.early_stop_metric == 'loss' and\n",
        "                       current < self.best_metric - self.config.min_delta) or \\\n",
        "                      (self.config.early_stop_metric != 'loss' and\n",
        "                       current > self.best_metric + self.config.min_delta)\n",
        "\n",
        "            if improved:\n",
        "                self.best_metric = current\n",
        "                self.best_model = self.model.state_dict().copy()\n",
        "                self.epochs_without_improve = 0\n",
        "                print(f\"Best {self.config.early_stop_metric}: {self.best_metric:.4f}\")\n",
        "                torch.save(self.model.state_dict(), f\"best_model_epoch_{epoch + 1}.pth\")\n",
        "            else:\n",
        "                self.epochs_without_improve += 1\n",
        "                if self.epochs_without_improve >= self.config.patience:\n",
        "                    print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "                    break\n",
        "\n",
        "            # Clear GPU memory\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        # Training completed\n",
        "        total_time = time.time() - start_time\n",
        "        print(f\"\\nTraining completed in {total_time:.2f}s\")\n",
        "\n",
        "        # Restore best model\n",
        "        self.model.load_state_dict(self.best_model)\n",
        "        wandb.save(\"best_model.pth\")\n",
        "\n",
        "        return self.model\n",
        "\n",
        "\n",
        "    def plot_metrics(self, final=False):\n",
        "        \"\"\"Plot training metrics\"\"\"\n",
        "        metrics = ['loss', 'accuracy', 'precision', 'f1']\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for ax, metric in zip(axes, metrics):\n",
        "            train_metric = [epoch[metric] for epoch in self.history['train']]\n",
        "            val_metric = [epoch[metric] for epoch in self.history['val']]\n",
        "            ax.plot(train_metric, label='Train')\n",
        "            ax.plot(val_metric, label='Val')\n",
        "\n",
        "            ax.set_title(f'{metric.capitalize()}')\n",
        "            ax.set_xlabel('Epochs')\n",
        "            ax.set_ylabel(metric.capitalize())\n",
        "            ax.legend()\n",
        "            ax.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if final:\n",
        "            plt.savefig('training_metrics.png')\n",
        "            plt.show()\n",
        "        else:\n",
        "            plt.draw()\n",
        "            plt.pause(0.1)\n",
        "        plt.close(fig)\n",
        "\n",
        "    def plot_confusion_matrix(self, loader, title=\"Confusion Matrix\"):\n",
        "        \"\"\"Plot confusion matrix on a given dataset (train/val/test)\"\"\"\n",
        "        self.model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in loader:\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                outputs = self.model(inputs)\n",
        "                preds = outputs.argmax(1)\n",
        "\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Compute confusion matrix\n",
        "        cm = confusion_matrix(all_labels, all_preds, labels=np.arange(self.config.num_classes))\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.arange(self.config.num_classes))\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        fig, ax = plt.subplots(figsize=(10, 10))\n",
        "        disp.plot(ax=ax, cmap=\"Blues\", values_format='d')\n",
        "        plt.title(title)\n",
        "        plt.savefig(f\"{title.replace(' ', '_').lower()}.png\")\n",
        "        plt.show()\n",
        "\n",
        "        # Log confusion matrix to W&B\n",
        "        wandb.log({title: wandb.Image(fig)})\n",
        "        plt.close(fig)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:44.32638Z",
          "iopub.execute_input": "2025-01-10T13:03:44.326696Z",
          "iopub.status.idle": "2025-01-10T13:03:44.353013Z",
          "shell.execute_reply.started": "2025-01-10T13:03:44.326634Z",
          "shell.execute_reply": "2025-01-10T13:03:44.352183Z"
        },
        "id": "54ENCdf5-EUt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create configuration\n",
        "config = TrainerConfig()\n",
        "config.num_classes = 2\n",
        "config.patience = 5\n",
        "config.learning_rate = 1e-4\n",
        "config.weight_decay = 1e-5\n",
        "\n",
        "criterion = WeightedMultiClassLogLoss(class_weights=class_weights_tensor)\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(model, criterion, config)\n",
        "\n",
        "# Train the model\n",
        "trained_model = trainer.train(train_loader, val_loader, epochs=20)"
      ],
      "metadata": {
        "trusted": true,
        "id": "iWpjeGy4-EUu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CCT Model"
      ],
      "metadata": {
        "id": "Ch5JzdLf-EUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SHI-Labs/Compact-Transformers.git"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:44.353842Z",
          "iopub.execute_input": "2025-01-10T13:03:44.354146Z",
          "iopub.status.idle": "2025-01-10T13:03:46.010832Z",
          "shell.execute_reply.started": "2025-01-10T13:03:44.354114Z",
          "shell.execute_reply": "2025-01-10T13:03:46.009944Z"
        },
        "id": "pAI6Bh8j-EUz",
        "outputId": "df65714e-3ff7-4568-bcbe-fd0f199d941b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Cloning into 'Compact-Transformers'...\nremote: Enumerating objects: 450, done.\u001b[K\nremote: Counting objects: 100% (175/175), done.\u001b[K\nremote: Compressing objects: 100% (68/68), done.\u001b[K\nremote: Total 450 (delta 131), reused 109 (delta 105), pack-reused 275 (from 1)\u001b[K\nReceiving objects: 100% (450/450), 1.34 MiB | 5.02 MiB/s, done.\nResolving deltas: 100% (243/243), done.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /kaggle/working/Compact-Transformers /kaggle/working/Compact_Transformers"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:46.011905Z",
          "iopub.execute_input": "2025-01-10T13:03:46.0122Z",
          "iopub.status.idle": "2025-01-10T13:03:46.167904Z",
          "shell.execute_reply.started": "2025-01-10T13:03:46.012174Z",
          "shell.execute_reply": "2025-01-10T13:03:46.166798Z"
        },
        "id": "VRk1kJr0-EUz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to a specific directory\n",
        "os.chdir('/kaggle/working/Compact_Transformers')\n",
        "\n",
        "# Verify the change\n",
        "print(f\"New Current Directory: {os.getcwd()}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:46.16904Z",
          "iopub.execute_input": "2025-01-10T13:03:46.169359Z",
          "iopub.status.idle": "2025-01-10T13:03:46.174552Z",
          "shell.execute_reply.started": "2025-01-10T13:03:46.169333Z",
          "shell.execute_reply": "2025-01-10T13:03:46.173516Z"
        },
        "id": "WRamWGbd-EUz",
        "outputId": "127e58f9-7b21-42ad-e505-f4665e4718d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "New Current Directory: /kaggle/working/Compact_Transformers\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CCT Class Wrapper"
      ],
      "metadata": {
        "id": "i0qciarsADuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryCCTWrapper(nn.Module):\n",
        "    def __init__(self, base_model, freeze_layers=True, dropout_rate=0.3, trainble_layers=5):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "\n",
        "        if freeze_layers:\n",
        "            for param in self.base_model.parameters():\n",
        "                param.requires_grad = False\n",
        "        else:\n",
        "            for param in self.base_model.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "            for block in self.base_model.classifier.blocks[-trainble_layers:]:\n",
        "                for param in block.parameters():\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            for param in self.base_model.classifier.norm.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "        in_features = self.base_model.classifier.fc.in_features\n",
        "\n",
        "        # Replace base model's classifier head\n",
        "        self.base_model.classifier.fc = nn.Sequential(\n",
        "            nn.LayerNorm(in_features),\n",
        "            nn.Linear(in_features, in_features * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(in_features * 2, in_features),\n",
        "            nn.LayerNorm(in_features),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(in_features, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:46.17551Z",
          "iopub.execute_input": "2025-01-10T13:03:46.175759Z",
          "iopub.status.idle": "2025-01-10T13:03:46.194524Z",
          "shell.execute_reply.started": "2025-01-10T13:03:46.175738Z",
          "shell.execute_reply": "2025-01-10T13:03:46.193806Z"
        },
        "id": "1aJ54vbn-EU0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from src.cct import cct_14_7x2_224\n",
        "# Instantiate the base CCT model\n",
        "base_model = cct_14_7x2_224(img_size=224, pretrained=True, progress=True)\n",
        "\n",
        "model = BinaryCCTWrapper(base_model=base_model, freeze_layers=False, dropout_rate=0.3)\n",
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:46.195588Z",
          "iopub.execute_input": "2025-01-10T13:03:46.195894Z",
          "iopub.status.idle": "2025-01-10T13:03:53.253365Z",
          "shell.execute_reply.started": "2025-01-10T13:03:46.195864Z",
          "shell.execute_reply": "2025-01-10T13:03:53.252585Z"
        },
        "id": "GZVw3qV2-EU0",
        "outputId": "3a906175-6534-41c5-fbf9-782195786e8a"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\nDownloading: \"https://shi-labs.com/projects/cct/checkpoints/pretrained/cct_14_7x2_224_imagenet.pth\" to /root/.cache/torch/hub/checkpoints/cct_14_7x2_224_imagenet.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85.4M/85.4M [00:05<00:00, 15.4MB/s]\n",
          "output_type": "stream"
        },
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "BinaryCCTWrapper(\n  (base_model): CCT(\n    (tokenizer): Tokenizer(\n      (conv_layers): Sequential(\n        (0): Sequential(\n          (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n          (1): ReLU()\n          (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n        )\n        (1): Sequential(\n          (0): Conv2d(64, 384, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n          (1): ReLU()\n          (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n        )\n      )\n      (flattener): Flatten(start_dim=2, end_dim=3)\n    )\n    (classifier): TransformerClassifier(\n      (attention_pool): Linear(in_features=384, out_features=1, bias=True)\n      (dropout): Dropout(p=0.0, inplace=False)\n      (blocks): ModuleList(\n        (0): TransformerEncoderLayer(\n          (pre_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (self_attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n            (attn_drop): Dropout(p=0.1, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (linear1): Linear(in_features=384, out_features=1152, bias=True)\n          (dropout1): Dropout(p=0.0, inplace=False)\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (linear2): Linear(in_features=1152, out_features=384, bias=True)\n          (dropout2): Dropout(p=0.0, inplace=False)\n          (drop_path): Identity()\n        )\n        (1-13): 13 x TransformerEncoderLayer(\n          (pre_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (self_attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n            (attn_drop): Dropout(p=0.1, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (linear1): Linear(in_features=384, out_features=1152, bias=True)\n          (dropout1): Dropout(p=0.0, inplace=False)\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (linear2): Linear(in_features=1152, out_features=384, bias=True)\n          (dropout2): Dropout(p=0.0, inplace=False)\n          (drop_path): DropPath()\n        )\n      )\n      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (fc): Sequential(\n        (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (1): Linear(in_features=384, out_features=768, bias=True)\n        (2): GELU(approximate='none')\n        (3): Dropout(p=0.3, inplace=False)\n        (4): Linear(in_features=768, out_features=384, bias=True)\n        (5): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (6): GELU(approximate='none')\n        (7): Dropout(p=0.3, inplace=False)\n        (8): Linear(in_features=384, out_features=2, bias=True)\n      )\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainerConfig:\n",
        "    def __init__(self):\n",
        "        self.num_classes = 2\n",
        "        self.patience = 3\n",
        "        self.min_delta = 1e-3\n",
        "        self.plot_interval = 2\n",
        "        self.max_grad_norm = 1.0\n",
        "        self.early_stop_metric = 'loss'\n",
        "        self.learning_rate = 3e-4\n",
        "        self.weight_decay = 1e-5\n",
        "        self.project_name = \"CCT-CLOT-Classifier\"\n",
        "        self.run_name = \"finetuning-runV2\"\n",
        "        self.batch_size=32\n",
        "        self.epochs = 20"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:53.254252Z",
          "iopub.execute_input": "2025-01-10T13:03:53.254461Z",
          "iopub.status.idle": "2025-01-10T13:03:53.259181Z",
          "shell.execute_reply.started": "2025-01-10T13:03:53.254442Z",
          "shell.execute_reply": "2025-01-10T13:03:53.258363Z"
        },
        "id": "-xPoxVXk-EU0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create configuration\n",
        "config = TrainerConfig()\n",
        "config.num_classes = 2\n",
        "config.patience = 5\n",
        "config.learning_rate = 1e-4\n",
        "config.weight_decay = 1e-5\n",
        "config.run_name = \"finetuning-run-temp1\"\n",
        "config.project_name = \"CCT-CLOT-ClassifierV4\"\n",
        "\n",
        "criterion = WeightedMultiClassLogLoss(class_weights=class_weights_tensor)\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(model, criterion, config)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:03:53.260234Z",
          "iopub.execute_input": "2025-01-10T13:03:53.260594Z",
          "iopub.status.idle": "2025-01-10T13:04:01.067494Z",
          "shell.execute_reply.started": "2025-01-10T13:03:53.260559Z",
          "shell.execute_reply": "2025-01-10T13:04:01.06684Z"
        },
        "id": "BOJEOPga-EU0",
        "outputId": "3291f6da-34cd-4a36-da2a-d73ef943c6da"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250110_130353-2qz9qt9n</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/mandour-cairo-university/CCT-CLOT-ClassifierV4/runs/2qz9qt9n' target=\"_blank\">iconic-butterfly-1</a></strong> to <a href='https://wandb.ai/mandour-cairo-university/CCT-CLOT-ClassifierV4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/mandour-cairo-university/CCT-CLOT-ClassifierV4' target=\"_blank\">https://wandb.ai/mandour-cairo-university/CCT-CLOT-ClassifierV4</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/mandour-cairo-university/CCT-CLOT-ClassifierV4/runs/2qz9qt9n' target=\"_blank\">https://wandb.ai/mandour-cairo-university/CCT-CLOT-ClassifierV4/runs/2qz9qt9n</a>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "trained_model = trainer.train(train_loader, val_loader, epochs=num_epochs)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T13:04:01.068289Z",
          "iopub.execute_input": "2025-01-10T13:04:01.068587Z",
          "iopub.status.idle": "2025-01-10T17:14:42.335446Z",
          "shell.execute_reply.started": "2025-01-10T13:04:01.068555Z",
          "shell.execute_reply": "2025-01-10T17:14:42.334513Z"
        },
        "id": "JuD7eZQN-EU0",
        "outputId": "9a61a4a2-75df-482b-8bfc-423aa93a74c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Starting training on device: cuda\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 1:   0%|          | 0/2966 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:769: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\nTraining Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:54<00:00,  6.25it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 2965. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 1/40 - Time: 506.80s\nTrain: loss: 1.2698 accuracy: 0.6321 precision: 0.6207 recall: 0.6321 f1: 0.6191\nVal: loss: 1.1634 accuracy: 0.6876 precision: 0.6746 recall: 0.6876 f1: 0.6767\nBest loss: 1.1634\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:38<00:00,  6.47it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 5931. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 2/40 - Time: 491.34s\nTrain: loss: 1.1740 accuracy: 0.6804 precision: 0.6668 recall: 0.6804 f1: 0.6687\nVal: loss: 1.1482 accuracy: 0.6959 precision: 0.7129 recall: 0.6959 f1: 0.7019\nBest loss: 1.1482\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:37<00:00,  6.49it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 8897. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 3/40 - Time: 490.21s\nTrain: loss: 1.1263 accuracy: 0.7007 precision: 0.6859 recall: 0.7007 f1: 0.6885\nVal: loss: 1.0587 accuracy: 0.7259 precision: 0.7314 recall: 0.7259 f1: 0.7284\nBest loss: 1.0587\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:36<00:00,  6.50it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 11863. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 4/40 - Time: 488.95s\nTrain: loss: 1.0883 accuracy: 0.7135 precision: 0.6979 recall: 0.7135 f1: 0.7011\nVal: loss: 1.0657 accuracy: 0.7283 precision: 0.7545 recall: 0.7283 f1: 0.7371\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:36<00:00,  6.50it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 14829. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 5/40 - Time: 489.44s\nTrain: loss: 1.0560 accuracy: 0.7258 precision: 0.7102 recall: 0.7258 f1: 0.7140\nVal: loss: 1.0313 accuracy: 0.7469 precision: 0.7578 recall: 0.7469 f1: 0.7515\nBest loss: 1.0313\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:35<00:00,  6.51it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 17795. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 6/40 - Time: 488.37s\nTrain: loss: 1.0253 accuracy: 0.7378 precision: 0.7221 recall: 0.7378 f1: 0.7263\nVal: loss: 0.9626 accuracy: 0.7616 precision: 0.7506 recall: 0.7616 f1: 0.7548\nBest loss: 0.9626\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:35<00:00,  6.51it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 20761. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 7/40 - Time: 488.67s\nTrain: loss: 1.0000 accuracy: 0.7458 precision: 0.7297 recall: 0.7458 f1: 0.7341\nVal: loss: 0.9456 accuracy: 0.7658 precision: 0.7520 recall: 0.7658 f1: 0.7567\nBest loss: 0.9456\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:36<00:00,  6.49it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 23727. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 8/40 - Time: 489.42s\nTrain: loss: 0.9739 accuracy: 0.7549 precision: 0.7384 recall: 0.7549 f1: 0.7431\nVal: loss: 0.9192 accuracy: 0.7753 precision: 0.7604 recall: 0.7753 f1: 0.7654\nBest loss: 0.9192\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:36<00:00,  6.50it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 26693. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 9/40 - Time: 489.60s\nTrain: loss: 0.9522 accuracy: 0.7626 precision: 0.7449 recall: 0.7626 f1: 0.7498\nVal: loss: 0.8935 accuracy: 0.7850 precision: 0.7738 recall: 0.7850 f1: 0.7783\nBest loss: 0.8935\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:35<00:00,  6.52it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 29659. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 10/40 - Time: 488.05s\nTrain: loss: 0.9313 accuracy: 0.7687 precision: 0.7513 recall: 0.7687 f1: 0.7564\nVal: loss: 0.8832 accuracy: 0.7846 precision: 0.7672 recall: 0.7846 f1: 0.7724\nBest loss: 0.8832\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:35<00:00,  6.51it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 11 that is less than the current step 32625. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 11/40 - Time: 488.54s\nTrain: loss: 0.9124 accuracy: 0.7763 precision: 0.7583 recall: 0.7763 f1: 0.7636\nVal: loss: 0.8629 accuracy: 0.7924 precision: 0.7804 recall: 0.7924 f1: 0.7851\nBest loss: 0.8629\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:35<00:00,  6.51it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 12 that is less than the current step 35591. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 12/40 - Time: 488.14s\nTrain: loss: 0.8864 accuracy: 0.7834 precision: 0.7664 recall: 0.7834 f1: 0.7719\nVal: loss: 0.8869 accuracy: 0.7887 precision: 0.7752 recall: 0.7887 f1: 0.7802\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:35<00:00,  6.51it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 13 that is less than the current step 38557. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 13/40 - Time: 488.11s\nTrain: loss: 0.8701 accuracy: 0.7890 precision: 0.7723 recall: 0.7890 f1: 0.7779\nVal: loss: 0.8303 accuracy: 0.8041 precision: 0.7932 recall: 0.8041 f1: 0.7977\nBest loss: 0.8303\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:34<00:00,  6.53it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 14 that is less than the current step 41523. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 14/40 - Time: 487.03s\nTrain: loss: 0.8561 accuracy: 0.7937 precision: 0.7762 recall: 0.7937 f1: 0.7820\nVal: loss: 0.8631 accuracy: 0.7954 precision: 0.7989 recall: 0.7954 f1: 0.7971\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:34<00:00,  6.52it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 15 that is less than the current step 44489. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 15/40 - Time: 487.33s\nTrain: loss: 0.8425 accuracy: 0.7988 precision: 0.7817 recall: 0.7988 f1: 0.7875\nVal: loss: 0.8214 accuracy: 0.8014 precision: 0.7952 recall: 0.8014 f1: 0.7980\nBest loss: 0.8214\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:34<00:00,  6.52it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 16 that is less than the current step 47455. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 16/40 - Time: 487.44s\nTrain: loss: 0.8268 accuracy: 0.8013 precision: 0.7839 recall: 0.8013 f1: 0.7898\nVal: loss: 0.7949 accuracy: 0.8136 precision: 0.8110 recall: 0.8136 f1: 0.8123\nBest loss: 0.7949\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:34<00:00,  6.53it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 17 that is less than the current step 50421. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 17/40 - Time: 486.88s\nTrain: loss: 0.8091 accuracy: 0.8068 precision: 0.7893 recall: 0.8068 f1: 0.7953\nVal: loss: 0.8033 accuracy: 0.8120 precision: 0.8025 recall: 0.8120 f1: 0.8066\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:34<00:00,  6.53it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 18 that is less than the current step 53387. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 18/40 - Time: 487.21s\nTrain: loss: 0.7976 accuracy: 0.8107 precision: 0.7933 recall: 0.8107 f1: 0.7994\nVal: loss: 0.7926 accuracy: 0.8163 precision: 0.8231 recall: 0.8163 f1: 0.8194\nBest loss: 0.7926\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:35<00:00,  6.51it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 19 that is less than the current step 56353. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 19/40 - Time: 488.90s\nTrain: loss: 0.7896 accuracy: 0.8137 precision: 0.7960 recall: 0.8137 f1: 0.8022\nVal: loss: 0.7796 accuracy: 0.8183 precision: 0.8055 recall: 0.8183 f1: 0.8106\nBest loss: 0.7796\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:34<00:00,  6.52it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 59319. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 20/40 - Time: 487.42s\nTrain: loss: 0.7709 accuracy: 0.8183 precision: 0.8005 recall: 0.8183 f1: 0.8068\nVal: loss: 0.7477 accuracy: 0.8276 precision: 0.8165 recall: 0.8276 f1: 0.8212\nBest loss: 0.7477\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:30<00:00,  6.58it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 21 that is less than the current step 62285. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 21/40 - Time: 482.95s\nTrain: loss: 0.7583 accuracy: 0.8217 precision: 0.8042 recall: 0.8217 f1: 0.8105\nVal: loss: 0.7566 accuracy: 0.8261 precision: 0.8242 recall: 0.8261 f1: 0.8251\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:28<00:00,  6.61it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 22 that is less than the current step 65251. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 22/40 - Time: 481.46s\nTrain: loss: 0.7483 accuracy: 0.8246 precision: 0.8068 recall: 0.8246 f1: 0.8132\nVal: loss: 0.7981 accuracy: 0.8240 precision: 0.8298 recall: 0.8240 f1: 0.8268\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:27<00:00,  6.63it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 23 that is less than the current step 68217. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 23/40 - Time: 480.17s\nTrain: loss: 0.7340 accuracy: 0.8293 precision: 0.8109 recall: 0.8293 f1: 0.8174\nVal: loss: 0.7510 accuracy: 0.8278 precision: 0.8280 recall: 0.8278 f1: 0.8279\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:28<00:00,  6.62it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 24 that is less than the current step 71183. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 24/40 - Time: 480.84s\nTrain: loss: 0.6806 accuracy: 0.8438 precision: 0.8273 recall: 0.8438 f1: 0.8337\nVal: loss: 0.7101 accuracy: 0.8374 precision: 0.8315 recall: 0.8374 f1: 0.8342\nBest loss: 0.7101\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:25<00:00,  6.66it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 25 that is less than the current step 74149. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 25/40 - Time: 477.51s\nTrain: loss: 0.6666 accuracy: 0.8472 precision: 0.8305 recall: 0.8472 f1: 0.8370\nVal: loss: 0.7052 accuracy: 0.8409 precision: 0.8411 recall: 0.8409 f1: 0.8410\nBest loss: 0.7052\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:21<00:00,  6.72it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 26 that is less than the current step 77115. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 26/40 - Time: 473.33s\nTrain: loss: 0.6543 accuracy: 0.8495 precision: 0.8330 recall: 0.8495 f1: 0.8395\nVal: loss: 0.6807 accuracy: 0.8474 precision: 0.8331 recall: 0.8474 f1: 0.8389\nBest loss: 0.6807\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:20<00:00,  6.73it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 27 that is less than the current step 80081. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 27/40 - Time: 472.80s\nTrain: loss: 0.6419 accuracy: 0.8538 precision: 0.8375 recall: 0.8538 f1: 0.8439\nVal: loss: 0.6923 accuracy: 0.8443 precision: 0.8426 recall: 0.8443 f1: 0.8435\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:23<00:00,  6.69it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 28 that is less than the current step 83047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 28/40 - Time: 476.17s\nTrain: loss: 0.6326 accuracy: 0.8563 precision: 0.8405 recall: 0.8563 f1: 0.8468\nVal: loss: 0.6931 accuracy: 0.8467 precision: 0.8441 recall: 0.8467 f1: 0.8453\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:20<00:00,  6.73it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 29 that is less than the current step 86013. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 29/40 - Time: 472.73s\nTrain: loss: 0.6203 accuracy: 0.8588 precision: 0.8428 recall: 0.8588 f1: 0.8492\nVal: loss: 0.6895 accuracy: 0.8490 precision: 0.8394 recall: 0.8490 f1: 0.8436\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:26<00:00,  6.65it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 30 that is less than the current step 88979. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 30/40 - Time: 478.29s\nTrain: loss: 0.5937 accuracy: 0.8662 precision: 0.8500 recall: 0.8662 f1: 0.8565\nVal: loss: 0.7048 accuracy: 0.8529 precision: 0.8498 recall: 0.8529 f1: 0.8513\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2966/2966 [07:21<00:00,  6.72it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 31 that is less than the current step 91945. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 31/40 - Time: 473.54s\nTrain: loss: 0.5847 accuracy: 0.8680 precision: 0.8514 recall: 0.8680 f1: 0.8580\nVal: loss: 0.6812 accuracy: 0.8553 precision: 0.8513 recall: 0.8553 f1: 0.8532\nEarly stopping at epoch 31\n\nTraining completed in 15041.25s\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(model, loader, device, num_classes, title=\"Confusion Matrix\", normalize=True):\n",
        "    \"\"\"\n",
        "    Plots a confusion matrix for the given model and dataset.\n",
        "\n",
        "    Args:\n",
        "        model: Trained PyTorch model.\n",
        "        loader: DataLoader for the dataset (train, val, or test).\n",
        "        device: Device ('cuda' or 'cpu') to perform computations.\n",
        "        num_classes: Number of classes in the dataset.\n",
        "        title: Title for the confusion matrix plot.\n",
        "        normalize: If True, normalize the confusion matrix by row.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            preds = outputs.argmax(1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=np.arange(num_classes))\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
        "        cm = np.nan_to_num(cm)  # Handle division by zero for rows with no samples\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.arange(num_classes))\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    cmap = \"Blues\" if normalize else None\n",
        "    values_format = \".2f\" if normalize else \"d\"\n",
        "    disp.plot(ax=ax, cmap=cmap, values_format=values_format)\n",
        "    plt.title(title)\n",
        "    plt.savefig(f\"{title.replace(' ', '_').lower()}.png\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T17:14:42.33769Z",
          "iopub.execute_input": "2025-01-10T17:14:42.337993Z",
          "iopub.status.idle": "2025-01-10T17:14:42.345376Z",
          "shell.execute_reply.started": "2025-01-10T17:14:42.337969Z",
          "shell.execute_reply": "2025-01-10T17:14:42.34473Z"
        },
        "id": "Gt7qhynH-EU0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(\n",
        "    model=model,\n",
        "    loader=val_loader,  # Or train_loader, test_loader, etc.\n",
        "    device=device,\n",
        "    num_classes=2,  # Replace with the actual number of classes\n",
        "    title=\"Validation Set Confusion Matrix\"\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T17:35:01.270952Z",
          "iopub.execute_input": "2025-01-10T17:35:01.271326Z",
          "iopub.status.idle": "2025-01-10T17:35:32.44362Z",
          "shell.execute_reply.started": "2025-01-10T17:35:01.271293Z",
          "shell.execute_reply": "2025-01-10T17:35:32.442878Z"
        },
        "id": "4yLE8do8-EU1",
        "outputId": "6902fb63-7bbe-485f-d1dd-668b5c43b6f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1000x1000 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}